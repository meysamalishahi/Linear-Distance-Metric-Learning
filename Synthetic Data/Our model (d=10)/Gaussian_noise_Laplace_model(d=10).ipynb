{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd283ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.distributions import Normal as norm\n",
    "from termcolor import colored\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import linalg as LA\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multinomial\n",
    "from numpy import genfromtxt\n",
    "from Main_functions import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322d4e9",
   "metadata": {},
   "source": [
    "### Setting the data distribuation \n",
    "\n",
    "Pairs $(x_i,y_i)\\in \\mathbb{R}^d\\times \\mathbb{R}^d$ for $i=1, \\ldots, N$ are generated i.i.d. from density distribuation $f(\\cdot)\\times f(\\cdot)$.  \n",
    "\n",
    "Parameters:\n",
    "\n",
    "$d:$ dimention of data points\n",
    "\n",
    "$N:$ number of pairs\n",
    "\n",
    "$f(\\cdot):$ density distribuation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848575ee",
   "metadata": {},
   "source": [
    "### Given the eigenvalue of ground truth $M_t$, we randomly generate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'CSVs/gaussian_laplace_'\n",
    "image_path = 'Images/gaussian_laplace_'\n",
    "title_suffix = '\\n (Gaussian Noise Laplace model)'\n",
    "noise_type = 'Gaussian'\n",
    "model_type = 'Laplace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3878c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 10\n",
    "rank = 5\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633aa25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "non_zero_eigens_of_M_star = np.round(np.random.uniform(low=0.0, high=1.0, size= rank), 2)\n",
    "non_zero_eigens_of_M_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = np.zeros(d)\n",
    "diag[:rank] = non_zero_eigens_of_M_star\n",
    "diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23087886",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = DG(diag, seed = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.M_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.M_t.shape, data_model.B_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a00b12",
   "metadata": {},
   "source": [
    "### Given the eigenvalue of covariance matrix Cov, we randomly generate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2024)\n",
    "diag_cov = np.round(np.random.uniform(low=0.0, high=1.0, size= d), 2)\n",
    "diag_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300736f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_cov.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma, U_sigma = random_covariance(diag_cov, seed = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591cfc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = multivariate_normal(mean = np.zeros(d), cov = Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d0341",
   "metadata": {},
   "source": [
    "### What is the average of squared norm of points generating where $x\\sim f(x)$ with $\\mathbb{E}(x) = \\mu$ and ${\\rm Cov}(x) = \\Sigma$\n",
    "\n",
    "If $x\\sim f(x)$ where $\\mathbb{E}(x) = \\mu$ and ${\\rm Cov}(x) = \\Sigma$, then \n",
    "\\begin{align}\n",
    "\\mathbb{E}\\left(x^\\top Mx\\right) & = \\mathbb{E}\\left({\\rm tr}(x^\\top Mx)\\right)\\\\\n",
    " & = \\mathbb{E}\\left({\\rm tr}(xx^\\top M)\\right)\\\\\n",
    " & = {\\rm tr}\\left(\\mathbb{E}\\left(xx^\\top\\right)M\\right)\\\\\n",
    " & = {\\rm tr}\\left(\\left[{\\rm Cov}(x) - \\mathbb{E}(x)\\mathbb{E}(x)^\\top\\right]M\\right)\n",
    "\\end{align}\n",
    "\n",
    "If we set  $\\mu = \\mathbf{0}$, then \n",
    "$$\\mathbb{E}\\left(x^\\top Mx\\right) = {\\rm tr}\\left(\\Sigma M\\right).$$\n",
    "Therefore, since $x$ and $y$ are independent, \n",
    "$$\\mathbb{E}\\left(\\|x-y\\|_M^2\\right) = 2{\\rm tr}\\left(\\Sigma M\\right).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "snm = 2 * np.trace(data_model.M_t @ Sigma)\n",
    "print(\"squared norm mean = {}\".format(snm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf4259",
   "metadata": {},
   "source": [
    "### Check the average empirically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ca841",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "X_1, Y_1 = sample(f, N)\n",
    "sn = (((X_1 - Y_1) @ data_model.B_t)**2).sum()/N\n",
    "print(\"emperical squared norm mean = {}\".format(sn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458e566",
   "metadata": {},
   "source": [
    "### Set $\\tau$ to generate data points (binary case!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be608fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = s* np.pi/np.sqrt(3)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = [1.3]\n",
    "N = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31307a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, D_noisy, D_no_noisy = data_model.generate(f, N, tau = np.array(tau), \n",
    "                                          noise_type = noise_type, noise_par = std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f50fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_amount = (D_noisy != D_no_noisy).mean()\n",
    "print('the amount of noise: {}'.format(noise_amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tau)+1):\n",
    "    print('number of pairs with {} as their labels is {}'.format(i,(D_no_noisy==i).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(D_no_noisy== 0).sum()/N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f093b",
   "metadata": {},
   "source": [
    "### Change to PyTorch tensor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype = torch.float64)\n",
    "Y = torch.tensor(Y, dtype = torch.float64)\n",
    "D_noisy = torch.tensor(D_noisy, dtype = torch.torch.int64)\n",
    "D_no_noisy = torch.tensor(D_no_noisy, dtype = torch.torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ac4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, D, X_T, Y_T, D_T, D_no_noise_T, X_test, Y_test, D_test, D_no_noise_test = train_test_split(X, \n",
    "                                                                                                 Y, \n",
    "                                                                                                 D_noisy, \n",
    "                                                                                                 D_no_noisy, \n",
    "                                                                                                 n_train = 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtype, D.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1399ee9",
   "metadata": {},
   "source": [
    "## Set the model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "n_labels = len(tau) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ML(d, k, n_labels, \n",
    "   X_T, Y_T, D_T, D_no_noise_T, \n",
    "   X_test, Y_test, D_test, D_no_noise_test, Type = model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(learning_rate = 5e-1, \n",
    "            n_iters = 30001, \n",
    "            decay = .95,\n",
    "            f = f, \n",
    "            B_star = data_model.B_t, \n",
    "            tau_star = data_model.tau_t, \n",
    "            N = 1000)\n",
    "# N here is used to generate N samples to estimate L_1_f_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, Y_new, _, D_new = data_model.generate(f, \n",
    "                                             N = 10000, \n",
    "                                             tau = np.array(tau), \n",
    "                                             noise_type = None, \n",
    "                                             noise_par = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = torch.tensor(X_new, dtype = torch.float64)\n",
    "Y_new = torch.tensor(Y_new, dtype = torch.float64)\n",
    "D_new = torch.tensor(D_new, dtype = torch.torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_unseen = model.accuracy(X_new, Y_new, D_new)\n",
    "print('accuracy on unseen data {}'.format(ac_unseen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abfe147",
   "metadata": {},
   "source": [
    "###  The variance of logistic distribution with scale $s$ is $\\sigma^2 = \\frac{s^2\\pi^2}{3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_prime = np.array(tau)[0]/model.Tau.detach().numpy()[0]\n",
    "# print(s_prime, s_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc09479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = std*np.sqrt(3)/np.pi\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cddfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hat = (model.B @ model.B.T).detach().numpy()*s\n",
    "M_star = data_model.M_t\n",
    "tau_hat = model.Tau.detach().numpy()[0]*s\n",
    "tau_star = data_model.tau_t[0]\n",
    "\n",
    "print((np.abs(M_hat - M_star)).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5073b1ab",
   "metadata": {},
   "source": [
    "### Relative errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e7ef0",
   "metadata": {},
   "source": [
    "$$\\frac{\\left\\|\\frac{\\hat{M}}{\\hat{\\tau}} - \\frac{M^*}{\\tau^*}\\right\\|_2}{\\left\\|\\frac{M^*}{\\tau^*}\\right\\|_2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hat_normal = model.B @ model.B.T / model.Tau[0]\n",
    "M_t_normal = data_model.M_t/tau[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de555ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((M_t_normal - M_hat_normal.detach().numpy())**2))/np.sqrt((M_t_normal**2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859eaa9",
   "metadata": {},
   "source": [
    "$$\\left\\|\\frac{\\hat{M}}{\\hat{\\tau}} - \\frac{M^*}{\\tau^*}\\right\\|_\\infty$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(M_t_normal - M_hat_normal.detach().numpy())).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6392f1f",
   "metadata": {},
   "source": [
    "$$\\left|\\frac{\\hat{M}}{\\hat{\\tau}} - \\frac{M^*}{\\tau^*}\\right|_{L_1(f)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_1_f_norm(f, model.B.detach().numpy(), model.Tau.detach().numpy(), \n",
    "           data_model.B_t, data_model.tau_t, N = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017ba5c",
   "metadata": {},
   "source": [
    "$$\\left|\\hat{\\tau} - \\frac{\\tau^*}{s}\\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(model.Tau.detach().numpy()[0] - data_model.tau_t[0]/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(M_t_normal - M_hat_normal.detach().numpy())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(M_t_normal - M_hat_normal.detach().numpy())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac90c2e-cdc8-49b6-9d0d-909ef9c8fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((M_t_normal - M_hat_normal.detach().numpy())**2))/np.sqrt((M_t_normal**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436cd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt((M_t_normal**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.Tau.detach().numpy())\n",
    "print(np.array(tau))\n",
    "print(np.array(tau)[0]/model.Tau.detach().numpy()[0], s, tau[0]/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47597f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_1_f_norm(f, model.B.detach().numpy(), model.Tau.detach().numpy(), \n",
    "           data_model.B_t, data_model.tau_t, N = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss(X_T - Y_T, D_T, data_model.B_t/np.sqrt(s), data_model.tau_t/s, Type = model_type).item())\n",
    "print(loss(X_T - Y_T, D_T, model.B, model.Tau, Type = model_type).item())\n",
    "print(model.loss_history[-1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss(X_T - Y_T, D_T, data_model.B_t/data_model.tau_t[0], np.zeros(1), Type = model_type).item())\n",
    "print(loss(X_T - Y_T, D_T, model.B/model.Tau[0], np.zeros(1), Type = model_type).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_test = pred(X_test, Y_test, data_model.B_t, np.array(tau))\n",
    "print(\"test accuracy with noise (Using ground truth) = \", (Pred_test == D_test).sum().item()/D_test.shape[0])\n",
    "print(\"test accuracy without noise (Using ground truth) = \", (Pred_test == D_no_noise_test).sum().item()/D_no_noise_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_test = pred(X_test, Y_test, model.B, model.Tau)\n",
    "print(\"test accuracy with noise\", (Pred_test == D_test).sum().item()/D_test.shape[0])\n",
    "print(\"test accuracy without noise\", (Pred_test == D_no_noise_test).sum().item()/D_no_noise_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a27e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_hat, S_hat, V_hat = LA.svd(M_hat_normal.detach().numpy(), full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa095a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_t, S_t, V_t = LA.svd(M_t_normal, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca829e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_hat.sum(), S_t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c13445",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(S_hat, label = 'eigenvalues of M_hat/tau_hat', color= 'red')\n",
    "plt.plot(S_t, label = 'eigenvalues of M_star/tau_star', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('#eigenvalue', fontsize=10)\n",
    "plt.ylabel('eigenvalue', fontsize=10)\n",
    "plt.title('eigenvalues of  M_hat/tau_hat and M_star/tau_star' + title_suffix, fontsize= 12)\n",
    "plt.savefig(image_path + 'eigen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0adca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(csv_path + \"eigen_S_star_normal.csv\", \n",
    "#            S_t,\n",
    "#            delimiter =\", \", \n",
    "#            fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"eigen.csv\", \n",
    "           S_hat,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = []\n",
    "m = 7\n",
    "for i in range(m):\n",
    "    H.append(proj(U_hat[:, i], U_t[:, :m]))\n",
    "    \n",
    "plt.plot([j+1 for j in range(m)], H, label = '1 - Cosine')\n",
    "plt.legend()\n",
    "plt.savefig(image_path + \"Cosine\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11640e1-0e2c-479c-8a71-4b1d3242bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"Cosine.csv\", \n",
    "           H,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(d):\n",
    "    print(np.dot(U_hat[:,i], U_t[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ba568",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(U_hat.T @ U_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af9a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "I = model.epoch_history\n",
    "plt.plot(I, model.train_accuracy_with_noise, label = 'train_accuracy_with_noise', color = 'black')\n",
    "plt.plot(I, model.train_accuracy_without_noise, label = 'train_accuracy_without_noise', color = 'red')\n",
    "plt.plot(I, model.test_accuracy_with_noise, label = 'test_accuracy_with_noise', color = 'green')\n",
    "plt.plot(I, model.test_accuracy_without_noise, label = 'test_accuracy_without_noise', color = 'blue')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('epoch', fontsize=10)\n",
    "plt.ylabel('accuracy', fontsize=10)\n",
    "plt.title('Test and Train accuracy vs epochs' + title_suffix, fontsize=12)\n",
    "plt.savefig(image_path + \"Test_and_Train_accuracy_vs_epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7697486f-ce97-45a8-be90-003618591693",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"model_epoch_history.csv\", \n",
    "           model.epoch_history,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd581dca-04f8-4e75-88f1-fd2f808be777",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"model_train_accuracy_with_noise.csv\", \n",
    "           model.train_accuracy_with_noise,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846cc64-a6cd-4835-bea5-b874edfebf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"model_train_accuracy_without_noise.csv\", \n",
    "           model.train_accuracy_without_noise,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bd515-10c6-4b8c-b7e5-2741d8542bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"model_test_accuracy_with_noise.csv\", \n",
    "           model.test_accuracy_with_noise,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b766558-f319-4a87-bd84-8fdfb728b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"model_test_accuracy_without_noise.csv\", \n",
    "           model.test_accuracy_without_noise,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.loss_history[-1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19661adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss(X_T - Y_T, D_T, model.B, model.Tau).item()\n",
    "l_value = loss(X_T - Y_T, D_T, data_model.B_t/np.sqrt(s), data_model.tau_t/s, Type = model_type).item()\n",
    "I_ = np.array([l_value for _ in I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbca89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(I[:], model.loss_history[:], label = 'loss_history', color = 'blue')\n",
    "plt.plot(I[:], I_[:], label = 'loss_on_M_star', color = 'red')\n",
    "plt.legend()\n",
    "plt.xlabel('# iteration', fontsize=10)\n",
    "plt.ylabel('loss', fontsize=10)\n",
    "plt.title('loss_history vs iteration' + title_suffix, fontsize=12)\n",
    "plt.savefig(image_path + \"loss_history_vs_iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313ca45-78c1-4f77-a0b0-dd4d53846aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"model.loss_history.csv\", \n",
    "           model.loss_history,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9b55b-c922-466f-880f-45f44617b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"true_loss_history.csv\", \n",
    "           I_,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L_1_f_norm_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56d7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(I[:], model.L_1_f_norm_history[:], label = 'L_1_f_norm_history', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('# iteration', fontsize=10)\n",
    "plt.ylabel('norm_history', fontsize=10)\n",
    "plt.title('L_1_f_norm_history vs iteration'+ title_suffix, fontsize=12)\n",
    "plt.savefig(image_path + \"_norm_history_vs_iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fe35f-4294-4e78-8196-f7e735bccd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"model_L_1_f_norm_history.csv\", \n",
    "           model.L_1_f_norm_history,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f1aca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sample complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 10\n",
    "k = 10\n",
    "n_labels = len(tau)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f21314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "H = []\n",
    "J = []\n",
    "N = 0\n",
    "while N <= 10000:\n",
    "    if N < 100:\n",
    "        N += 10\n",
    "    elif N < 1000:\n",
    "        N += 100\n",
    "    elif N < 5000:\n",
    "        N+= 1000\n",
    "    else: N += 5000\n",
    "    \n",
    "    \n",
    "    X, Y, D_noisy, D_no_noisy = data_model.generate(f, \n",
    "                                                    N + 2000, \n",
    "                                                    tau = np.array(tau), \n",
    "                                                    noise_type = noise_type, \n",
    "                                                    noise_par = std)\n",
    "    X = torch.tensor(X, dtype = torch.float64)\n",
    "    Y = torch.tensor(Y, dtype = torch.float64)\n",
    "    D_noisy = torch.tensor(D_noisy, dtype = torch.torch.int64)\n",
    "    D_no_noisy = torch.tensor(D_no_noisy, dtype = torch.torch.int64)\n",
    "        \n",
    "    print('round for N = {} has started'.format(N))\n",
    "    \n",
    "    J.append(N)\n",
    "    X, Y, D, X_T, Y_T, D_T, D_no_noise_T, X_test, Y_test, D_test, D_no_noise_test = train_test_split(X, \n",
    "                                                                                                     Y, \n",
    "                                                                                                 D_noisy, \n",
    "                                                                                                 D_no_noisy, \n",
    "                                                                                                 n_train = N)\n",
    "    model = ML(d, k, n_labels, \n",
    "               X_T, Y_T, \n",
    "               D_T, D_no_noise_T, \n",
    "               X_test, Y_test, \n",
    "               D_test, D_no_noise_test, Type = model_type) \n",
    "    \n",
    "    model.train(learning_rate = 2e-1, \n",
    "                n_iters = 30000, \n",
    "                decay = .99, \n",
    "                show_log = False)\n",
    "    H.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "H[-1].accuracy(X_new, Y_new, D_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_no_noise  = [H[i].accuracy(X_new, Y_new, D_new) for i in range(len(H))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(J, test_accuracy_no_noise, label = 'test_accuracy (no noise)', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('# samples', fontsize=10)\n",
    "plt.ylabel('accuracy', fontsize=10)\n",
    "plt.title('test_accuracy (no noise) vs sample complexity' + title_suffix, fontsize=12)\n",
    "plt.savefig(image_path + \"test_accuracy_(no_noise)_vs_sample_complexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4f89d-ff98-4eb8-b169-63263c35fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"test_accuracy_no_noise.csv\", \n",
    "           test_accuracy_no_noise,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b486c-e2db-47d4-b9c8-0744e57b718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"number_samples_list.csv\", \n",
    "           J,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_noisy  = [H[i].accuracy(H[i].X_test, H[i].Y_test, H[i].D_test) for i in range(len(H))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058044e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(J, test_accuracy_noisy, label = 'test_accuracy(noisy)', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('# samples', fontsize=10)\n",
    "plt.ylabel('accuracy', fontsize=10)\n",
    "plt.title('test_accuracy (noisy) vs sample complexity'+ title_suffix, fontsize=10)\n",
    "plt.savefig(image_path + 'test_accuracy_(noisy)_vs_sample_complexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38584f7a-92ec-4f93-b46d-36c358c5283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"test_accuracy_noisy.csv\", \n",
    "           test_accuracy_noisy,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09015211",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_noisy  = [H[i].accuracy(H[i].X_T, H[i].Y_T, H[i].D_T) for i in range(len(H))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6baea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(J, train_accuracy_noisy, label = 'train_accuracy (noisy)', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('# samples', fontsize=10)\n",
    "plt.ylabel('accuracy', fontsize=10)\n",
    "plt.title('train_accuracy (noisy) vs sample complexity' + title_suffix, fontsize=12)\n",
    "plt.savefig(image_path + \"train_accuracy_(noisy)_vs_sample_complexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db5531-5bab-4937-83f1-9c7528fa8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"train_accuracy_noisy.csv\", \n",
    "           train_accuracy_noisy,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_no_noisy  = [H[i].accuracy(H[i].X_T, H[i].Y_T, H[i].D_no_noise_T) for i in range(len(H))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(J, train_accuracy_no_noisy, label = 'train_accuracy (no noise)', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('# samples', fontsize=10)\n",
    "plt.ylabel('accuracy', fontsize=10)\n",
    "plt.title('train_accuracy (no noise) vs sample complexity' +  title_suffix, fontsize=12)\n",
    "plt.savefig(image_path + \"train_accuracy_(no_noise)_vs_sample_complexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940249e1-0418-4dd9-a112-a3111aeaa35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"train_accuracy_no_noisy.csv\", \n",
    "           train_accuracy_no_noisy,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(J, train_accuracy_no_noisy, label = 'train_accuracy (no noise)', color = 'blue')\n",
    "plt.plot(J, train_accuracy_noisy, label = 'train_accuracy (noisy)', color = 'red')\n",
    "plt.plot(J, test_accuracy_noisy, label = 'test_accuracy(noisy)', color = 'green')\n",
    "plt.plot(J, test_accuracy_no_noise, label = 'test_accuracy (no noise)', color = 'magenta')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('# samples', fontsize=10)\n",
    "plt.ylabel('accuracy', fontsize=10)\n",
    "plt.title('accuracy vs sample complexity' + title_suffix, fontsize=12)\n",
    "plt.savefig(image_path + \"accuracy_vs_sample_complexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef7cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "I = H[-1].epoch_history[:]\n",
    "plt.plot(I, H[-1].train_accuracy_with_noise[:], label = 'train_accuracy_with_noise', color = 'black')\n",
    "plt.plot(I, H[-1].train_accuracy_without_noise[:], label = 'train_accuracy_without_noise', color = 'red')\n",
    "plt.plot(I, H[-1].test_accuracy_with_noise[:], label = 'test_accuracy_with_noise', color = 'green')\n",
    "plt.plot(I, H[-1].test_accuracy_without_noise[:], label = 'test_accuracy_without_noise', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('# Epoch', fontsize=10)\n",
    "plt.ylabel('Accuracy', fontsize=10)\n",
    "plt.title('Accuracy vs Epoch' + title_suffix, fontsize=12)\n",
    "plt.savefig(image_path + 'Accuracy_vs_Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058abf04-d819-4c23-84dd-aae281a937b1",
   "metadata": {},
   "source": [
    "### How much noise breaks the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d40a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_par_list = [i/10 for i in range(11)] + [1+ i/5 for i in range(1,6)] + [2.5, 4, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_list = [s_ * np.pi/np.sqrt(3) for s_ in noise_par_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528834e9-5083-4a9e-98cf-bd7081b07d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tau)\n",
    "N = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f333a-5bf2-47d8-bae0-85e997e0b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, D_noisy, D_no_noisy = data_model.generate(f, N = 20000, tau = np.array(tau), \n",
    "                                          noise_type = noise_type, noise_par = 40)\n",
    "noise_amount = (D_noisy != D_no_noisy).mean()\n",
    "print('the amount of noise: {}'.format(noise_amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740f579-64bd-49b5-80df-2047886052c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(D_no_noisy == 0).sum(), (D_no_noisy == 1).sum(), (D_no_noisy == 1).sum()/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17022771-beac-4538-b65e-c32f5888bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_par_list = [0, .2, .5, .8, 1.1, 1.4, 1.85, 2., 2.3, 2.5, 2.8, 2.9, 3.1,\n",
    "#  3.9, 4.1, 4.35, 4.4, 4.5, 4.6, 4.8, 7.5, 12.5, 27, 60, 80, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280101ca-a7ab-495d-9585-6fec44078492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"CSVs/Gaussian/scale_list.csv\", \n",
    "#            noise_par_list,\n",
    "#            delimiter =\", \", \n",
    "#            fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffff23-a025-4a6a-86b4-48e3b3bea900",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=20000\n",
    "d = 10\n",
    "k = 10\n",
    "n_labels = len(tau) + 1\n",
    "noise_list_history = []\n",
    "model_history = []\n",
    "for std_ in std_list:\n",
    "    X, Y, D_noisy, D_no_noisy = data_model.generate(f, N, tau = np.array(tau), \n",
    "                                                    noise_type = noise_type, noise_par = std_)\n",
    "    noise_amount = (D_noisy != D_no_noisy).mean()\n",
    "    print('the amount of noise: {}'.format(noise_amount))\n",
    "    noise_list_history.append(noise_amount)\n",
    "    \n",
    "    X = torch.tensor(X, dtype = torch.float64)\n",
    "    Y = torch.tensor(Y, dtype = torch.float64)\n",
    "    D_noisy = torch.tensor(D_noisy, dtype = torch.torch.int64)\n",
    "    D_no_noisy = torch.tensor(D_no_noisy, dtype = torch.torch.int64)\n",
    "    \n",
    "    X,Y,D,X_T, Y_T,D_T,D_no_noise_T, X_test,Y_test,D_test,D_no_noise_test = train_test_split(X,\n",
    "                                                                                             Y, \n",
    "                                                                                             D_noisy, \n",
    "                                                                                             D_no_noisy,\n",
    "                                                                                             n_train = 18000)\n",
    "    model = ML(d, k, n_labels, \n",
    "               X_T, Y_T, D_T, D_no_noise_T,\n",
    "               X_test, Y_test, D_test, D_no_noise_test, Type = model_type)\n",
    "    \n",
    "    model.train(learning_rate = 1e-1, \n",
    "                n_iters = 30001, \n",
    "                decay = .95, \n",
    "                show_log = False)\n",
    "    \n",
    "    model_history.append(model)\n",
    "    \n",
    "    print('train_accuracy (noisey) = {}'.format(model_history[-1].accuracy(model_history[-1].X_T, \n",
    "                                                                           model_history[-1].Y_T, \n",
    "                                                                           model_history[-1].D_T)))\n",
    "    \n",
    "    print('test_accuracy (noisey) = {}'.format(model_history[-1].accuracy(model_history[-1].X_test, \n",
    "                                                                          model_history[-1].Y_test, \n",
    "                                                                          model_history[-1].D_test)))\n",
    "    \n",
    "    print('train_accuracy (no noise) = {}'.format(model_history[-1].accuracy(model_history[-1].X_T, \n",
    "                                                                             model_history[-1].Y_T, \n",
    "                                                                             model_history[-1].D_no_noise_T)))\n",
    "    \n",
    "    print('test_accuracy (no noise) = {}'.format(model_history[-1].accuracy(model_history[-1].X_test, \n",
    "                                                                            model_history[-1].Y_test, \n",
    "                                                                            model_history[-1].D_no_noise_test)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea0e84-bce5-4834-957e-c82268b13c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"noise_list_history.csv\", \n",
    "           noise_list_history,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2d3b5-ab18-4cfb-8ac9-e15d9976d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(noise_par_list, noise_list_history, label = 'variance VS noise', color = 'blue')\n",
    "plt.legend()\n",
    "plt.ylabel('# Noise', fontsize = 10)\n",
    "plt.xlabel('variance', fontsize = 10)\n",
    "plt.title('Noise vs variance [Gaussian]', fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b00f6d-f29e-4062-a35b-a78e1e711be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, Y_new, _, D_new = data_model.generate(f, \n",
    "                                             N = 10000, \n",
    "                                             tau = np.array(tau), \n",
    "                                             noise_type = None, \n",
    "                                             noise_par = None)\n",
    "X_new = torch.tensor(X_new, dtype = torch.float64)\n",
    "Y_new = torch.tensor(Y_new, dtype = torch.float64)\n",
    "D_new = torch.tensor(D_new, dtype = torch.torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576bad07-e301-4a7e-bee9-bed8e548a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_no_noise  = [model_history[i].accuracy(X_new, Y_new, D_new) for i in range(len(model_history))]\n",
    "\n",
    "plt.plot(noise_list_history, test_accuracy_no_noise, label = 'test_accuracy (no noise)', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('noise', fontsize = 10)\n",
    "plt.ylabel('accuracy', fontsize = 10)\n",
    "plt.title('test_accuracy (no noise) vs noise' + title_suffix, fontsize = 12)\n",
    "plt.savefig(image_path + 'Test_accuracy_(no_noise)_vs_noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c39af2-c2f3-43f6-8fca-9a0117fc99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"test_accuracy_no_noise.csv\", \n",
    "           test_accuracy_no_noise,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(noise_list_history[i], test_accuracy_no_noise[i]) for i in range(len(noise_list_history))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b3f90-e449-4148-9304-dd4a4c254a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_noisy  = [model_history[i].accuracy(model_history[i].X_test, \n",
    "                                                  model_history[i].Y_test, \n",
    "                                                  model_history[i].D_test) for i in range(len(model_history))]\n",
    "\n",
    "plt.plot(noise_list_history, test_accuracy_noisy, label = 'test_accuracy(noisy)', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('noise', fontsize = 10)\n",
    "plt.ylabel('accuracy', fontsize = 10)\n",
    "plt.title('test_accuracy (noisy) vs noise' + title_suffix, fontsize = 12)\n",
    "plt.savefig(image_path + 'test_accuracy_(noisy)_vs_noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c234b-216c-43c0-8bf9-0437a129ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"test_accuracy_noisy.csv\", \n",
    "           test_accuracy_noisy,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377532e-1689-480c-a0cb-0fd8def472d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_noisy  = [model_history[i].accuracy(model_history[i].X_T, \n",
    "                                                   model_history[i].Y_T, \n",
    "                                                   model_history[i].D_T) for i in range(len(model_history))]\n",
    "\n",
    "plt.plot(noise_list_history, train_accuracy_noisy, label = 'train_accuracy (noisy)', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('noise', fontsize = 10)\n",
    "plt.ylabel('accuracy', fontsize = 10)\n",
    "plt.title('train_accuracy (noisy) vs noise' + title_suffix, fontsize = 10)\n",
    "plt.savefig(image_path + 'train_accuracy_(noisy)_vs_noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e0938-653c-44ba-beab-fbaa8a435195",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"train_accuracy_noisy.csv\", \n",
    "           train_accuracy_noisy,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818ebd1-4762-40e7-99b3-8386163ea856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_accuracy_no_noisy  = [model_history[i].accuracy(model_history[i].X_T, \n",
    "                                                      model_history[i].Y_T, \n",
    "                                                      model_history[i].D_no_noise_T) for i in range(len(model_history))]\n",
    "plt.plot(noise_list_history, \n",
    "         train_accuracy_no_noisy, \n",
    "         label = 'train_accuracy (no noise)', \n",
    "         color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('noise', fontsize = 10)\n",
    "plt.ylabel('accuracy', fontsize = 10)\n",
    "plt.title('train_accuracy (no noise) vs noise' + title_suffix, fontsize = 12)\n",
    "plt.savefig(image_path + 'train_accuracy_(no_noise)_vs_noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3542aa3-7b2d-4953-844a-8ba5cdeaaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(csv_path + \"train_accuracy_no_noisy.csv\", \n",
    "           train_accuracy_no_noisy,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_list_history[-1], train_accuracy_no_noisy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5264cdf-415e-47d6-ad31-f987d6ba94b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
