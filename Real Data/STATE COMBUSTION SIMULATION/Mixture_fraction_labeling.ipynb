{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c6515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.distributions import Normal as norm\n",
    "from termcolor import colored\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import linalg as LA\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multinomial\n",
    "from scipy.stats import logistic\n",
    "from Main_functions import *\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b22514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_pre_process = 'center_scaling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52eb0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_for_projected_data = 'hydrogen-combustion-3D-autoencoder-projection-of-state-space.csv'\n",
    "path_for_actual_data = 'RawData/hydrogen-combustion-state-space.csv'\n",
    "M_path = 'Matrices/hydrogen-combustion-3D-autoencoder-basis.csv'\n",
    "mixture_fraction_path = 'RawData/hydrogen-combustion-mixture-fraction.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102dda1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_for_projected_data = 'syngas-combustion-3D-autoencoder-projection-of-state-space.csv'\n",
    "\n",
    "# path_for_actual_data = 'RawData/syngas-combustion-state-space.csv'\n",
    "# M_path = 'Matrices/syngas-combustion-3D-autoencoder-basis.csv'\n",
    "# mixture_fraction_path = 'RawData/syngas-combustion-mixture-fraction.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c24f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 9), (30000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw = genfromtxt(path_for_actual_data, delimiter = ',')\n",
    "mixture_fractions = genfromtxt(mixture_fraction_path, delimiter = ',')\n",
    "X_raw.shape, mixture_fractions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b093e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.22699981e+03, 2.80194937e-04, 5.74208493e-02, 2.04368036e-06,\n",
       "        3.65208097e-04, 2.40747110e-01, 8.23686066e-07, 1.01962996e-09,\n",
       "        1.02021563e-09]),\n",
       " 0.08466189136909588)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw[10000], mixture_fractions[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d6ed15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(Type = 'normalizing'):\n",
    "    \n",
    "    X_new = (X_raw - X_raw.mean(axis = 0))\n",
    "    \n",
    "    if Type == 'normalizing':\n",
    "        std = X_new.std(axis = 0)\n",
    "        for i in range(len(std)):\n",
    "            if std[i] > 1e-3:\n",
    "                X_new[:, i] /= std[i]\n",
    "        \n",
    "    elif Type == 'center_scaling':\n",
    "        Max = X_new.max(axis = 0)\n",
    "        Min = X_new.min(axis = 0)\n",
    "        for i in range(len(Max)):\n",
    "            if Max[i] - Min[i] > 1e-3:\n",
    "                X_new[:, i]  = (X_new[:, i] - Min[i])/(Max[i]-Min[i])\n",
    "            else: X_new[:, i]  = (X_new[:, i] - Min[i])\n",
    "                \n",
    "    elif Type == 'no_normalizing': return X_raw\n",
    "                \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc33097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed = pre_process(Type = type_of_pre_process)\n",
    "n, d = X_processed.shape\n",
    "X_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ad40f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixture_fractions.min(), mixture_fractions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce419e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D = (mixture_fractions>= 0.33)\n",
    "D = (mixture_fractions>= 0.15)\n",
    "D.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "277ba93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30000\n",
    "n_trn = 15000\n",
    "I = random.choices(np.arange(n), k = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30746706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51013333])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed_I = X_processed[I]\n",
    "X_processed_J = np.zeros(X_processed[I].shape)\n",
    "D_I = D[I]\n",
    "D_I.sum()/D_I.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103c694",
   "metadata": {},
   "source": [
    "### Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d24ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X_processed_I, dtype = torch.float64)\n",
    "Y = torch.tensor(X_processed_J, dtype = torch.float64)\n",
    "D = torch.tensor(D_I, dtype = torch.torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76c13512",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T = X[:n_trn,:]\n",
    "Y_T = Y[:n_trn,:]\n",
    "D_T = D[:n_trn]\n",
    "\n",
    "X_test = X[n_trn:,:]\n",
    "Y_test = Y[n_trn:,:]\n",
    "D_test = D[n_trn:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c38adb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30000, 9]), torch.Size([30000, 9]), torch.Size([30000]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4bf2be",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c77ed2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = d\n",
    "n_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e81439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ML(d, k, n_labels, \n",
    "           X_T, Y_T, D_T, D_T, \n",
    "           X_test, Y_test, D_test, D_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5de54b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Tau:  tensor([0.8201], dtype=torch.float64, requires_grad=True)\n",
      "epoch 0: loss = 0.7871000008795709\n",
      "train accuracy with noise 0.4852\n",
      "train accuracy without noise 0.4852\n",
      "test accuracy with noise 0.4945333333333333\n",
      "test accuracy without noise 0.4945333333333333\n",
      "epoch 1:\n",
      " norm of B.grad = 1.7215131796273463e-12,\n",
      " B.grad.max = 7.64537994790864e-07,\n",
      " loss = 0.7871000008795709\n",
      "tensor([0.7156], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.4852\n",
      "train accuracy without noise 0.4852\n",
      "test accuracy with noise 0.4945333333333333\n",
      "test accuracy without noise 0.4945333333333333\n",
      "epoch 5001:\n",
      " norm of B.grad = 4.610258356420841e-06,\n",
      " B.grad.max = 0.001626426280280686,\n",
      " loss = 0.030107658169938212\n",
      "tensor([10.1804], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9974\n",
      "train accuracy without noise 0.9974\n",
      "test accuracy with noise 0.9970666666666667\n",
      "test accuracy without noise 0.9970666666666667\n",
      "epoch 10001:\n",
      " norm of B.grad = 1.7565038793380547e-06,\n",
      " B.grad.max = 0.0010073592341820802,\n",
      " loss = 0.022291003425816674\n",
      "tensor([12.2428], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9978\n",
      "train accuracy without noise 0.9978\n",
      "test accuracy with noise 0.9974666666666666\n",
      "test accuracy without noise 0.9974666666666666\n",
      "epoch 15001:\n",
      " norm of B.grad = 1.0451832662691456e-06,\n",
      " B.grad.max = 0.0007775078425108003,\n",
      " loss = 0.018926927969087626\n",
      "tensor([13.5244], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9980666666666667\n",
      "train accuracy without noise 0.9980666666666667\n",
      "test accuracy with noise 0.9979333333333333\n",
      "test accuracy without noise 0.9979333333333333\n",
      "epoch 20001:\n",
      " norm of B.grad = 7.415112652476925e-07,\n",
      " B.grad.max = 0.0006546743219380379,\n",
      " loss = 0.016962252903412006\n",
      "tensor([14.4501], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9982\n",
      "train accuracy without noise 0.9982\n",
      "test accuracy with noise 0.9981333333333333\n",
      "test accuracy without noise 0.9981333333333333\n",
      "epoch 25001:\n",
      " norm of B.grad = 5.779075720517798e-07,\n",
      " B.grad.max = 0.0005775770567181329,\n",
      " loss = 0.01564975734231165\n",
      "tensor([15.1655], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9982666666666666\n",
      "train accuracy without noise 0.9982666666666666\n",
      "test accuracy with noise 0.9984666666666666\n",
      "test accuracy without noise 0.9984666666666666\n",
      "epoch 30001:\n",
      " norm of B.grad = 4.77376690273481e-07,\n",
      " B.grad.max = 0.0005245425297228984,\n",
      " loss = 0.014703466001282273\n",
      "tensor([15.7403], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9983333333333333\n",
      "train accuracy without noise 0.9983333333333333\n",
      "test accuracy with noise 0.9984666666666666\n",
      "test accuracy without noise 0.9984666666666666\n"
     ]
    }
   ],
   "source": [
    "model.train(learning_rate = 5e-1, #4e-1, decay = 0.9 accuracy = 73.75% is the best so far\n",
    "            n_iters = 30001, \n",
    "            decay = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "944804ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hat = (model.B @ model.B.T).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3c619cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.7403, dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Tau[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5503d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hat_normal = model.B @ model.B.T / model.Tau[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4245cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"B_hat_normal_hydrogen_1.csv\", \n",
    "           model.B.detach().numpy()/np.sqrt(model.Tau[0].item()),\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4a92d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_hat, S_hat, V_hat = LA.svd(M_hat_normal.detach().numpy(), full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee10ea41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.01896662e+01, 6.74059676e-13, 2.48427979e-13, 1.55530348e-13,\n",
       "       2.56059186e-14, 7.94528629e-16, 1.38570901e-16, 3.32441735e-17,\n",
       "       3.34542782e-18])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64b00f",
   "metadata": {},
   "source": [
    "### Pair distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "070c3d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed = pre_process(Type = type_of_pre_process)\n",
    "N, d = X_processed.shape\n",
    "X_processed.shape\n",
    "N, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74c1f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perm = permutations([i for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7e7b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Range = [i for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b80f59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "555a4935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22124, 24177, 18415, 12936, 24687, 451, 5321, 28816, 18141, 18987]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Range[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e42ad5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = [Range[2*i] for i in range(N//2)]\n",
    "J = [Range[2*i+1] for i in range(N//2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "708cc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 30000\n",
    "# n_trn = 15000\n",
    "# I = random.choices(np.arange(n), k = N)\n",
    "# J = random.choices(np.arange(n), k = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2680a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed_I = X_processed[I]\n",
    "X_processed_J = X_processed[J]\n",
    "D_I = mixture_fractions[I]\n",
    "D_J = mixture_fractions[J]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64313f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_diff = np.abs(D_I - D_J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f6e8053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.270066493290085"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3511751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7254"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = (D_diff >= 0.2)\n",
    "D.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13dd7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trn = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75d56d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X_processed_I, dtype = torch.float64)\n",
    "Y = torch.tensor(X_processed_J, dtype = torch.float64)\n",
    "D = torch.tensor(D, dtype = torch.torch.int64)\n",
    "\n",
    "X_T = X[:n_trn,:]\n",
    "Y_T = Y[:n_trn,:]\n",
    "D_T = D[:n_trn]\n",
    "\n",
    "X_test = X[n_trn:,:]\n",
    "Y_test = Y[n_trn:,:]\n",
    "D_test = D[n_trn:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0dc611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "n_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "608b9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ML(d, k, n_labels, \n",
    "           X_T, Y_T, D_T, D_T, \n",
    "           X_test, Y_test, D_test, D_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c4d1ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Tau:  tensor([0.5080], dtype=torch.float64, requires_grad=True)\n",
      "epoch 0: loss = 0.7160210483136028\n",
      "train accuracy with noise 0.5178\n",
      "train accuracy without noise 0.5178\n",
      "test accuracy with noise 0.5136\n",
      "test accuracy without noise 0.5136\n",
      "epoch 1:\n",
      " norm of B.grad = 1.828148713298446e-13,\n",
      " B.grad.max = 2.6589487598606944e-07,\n",
      " loss = 0.7160210483136028\n",
      "tensor([0.4547], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.5178\n",
      "train accuracy without noise 0.5178\n",
      "test accuracy with noise 0.5136\n",
      "test accuracy without noise 0.5136\n",
      "epoch 5001:\n",
      " norm of B.grad = 9.783603188247391e-07,\n",
      " B.grad.max = 0.0007939880324709032,\n",
      " loss = 0.023567172207458235\n",
      "tensor([10.5399], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9972\n",
      "train accuracy without noise 0.9972\n",
      "test accuracy with noise 0.9974\n",
      "test accuracy without noise 0.9974\n",
      "epoch 10001:\n",
      " norm of B.grad = 3.5446803554166025e-07,\n",
      " B.grad.max = 0.0004827819470484274,\n",
      " loss = 0.018832512379482403\n",
      "tensor([13.2064], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9977\n",
      "train accuracy without noise 0.9977\n",
      "test accuracy with noise 0.9976\n",
      "test accuracy without noise 0.9976\n",
      "epoch 15001:\n",
      " norm of B.grad = 2.1044881976502095e-07,\n",
      " B.grad.max = 0.00037110037099897207,\n",
      " loss = 0.016651892511417486\n",
      "tensor([14.9553], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9979\n",
      "train accuracy without noise 0.9979\n",
      "test accuracy with noise 0.9976\n",
      "test accuracy without noise 0.9976\n",
      "epoch 20001:\n",
      " norm of B.grad = 1.5068158516265135e-07,\n",
      " B.grad.max = 0.00031201109365975265,\n",
      " loss = 0.015325677228931227\n",
      "tensor([16.2569], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9981\n",
      "train accuracy without noise 0.9981\n",
      "test accuracy with noise 0.9976\n",
      "test accuracy without noise 0.9976\n",
      "epoch 25001:\n",
      " norm of B.grad = 1.187280388396553e-07,\n",
      " B.grad.max = 0.0002749862114971282,\n",
      " loss = 0.014414773653528317\n",
      "tensor([17.2828], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9983\n",
      "train accuracy without noise 0.9983\n",
      "test accuracy with noise 0.9978\n",
      "test accuracy without noise 0.9978\n",
      "epoch 30001:\n",
      " norm of B.grad = 9.902951279531008e-08,\n",
      " B.grad.max = 0.0002494627820477222,\n",
      " loss = 0.013744622775248422\n",
      "tensor([18.1186], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.9983\n",
      "train accuracy without noise 0.9983\n",
      "test accuracy with noise 0.9978\n",
      "test accuracy without noise 0.9978\n"
     ]
    }
   ],
   "source": [
    "model.train(learning_rate = 5e-1, #4e-1, decay = 0.9 accuracy = 73.75% is the best so far\n",
    "            n_iters = 30001, \n",
    "            decay = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2a6e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hat = (model.B @ model.B.T).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f7f85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = model.Tau[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2926a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hat_normal = model.B @ model.B.T / model.Tau[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1b1f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"B_hat_normal_hydrogen_2.csv\", \n",
    "           model.B.detach().numpy()/np.sqrt(model.Tau[0].item()),\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "005c0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_hat, S_hat, V_hat = LA.svd(M_hat_normal.detach().numpy(), full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "965d656d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.46515024e+01, 5.67054607e-13, 9.17032207e-14, 1.14443500e-15,\n",
       "       2.43618164e-16, 3.11493634e-17, 9.66401092e-18, 3.60552444e-18,\n",
       "       1.64271950e-19])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0ea53",
   "metadata": {},
   "source": [
    "### Without normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85d848dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed = pre_process(Type = 'no_normalizing')\n",
    "N, d = X_processed.shape\n",
    "X_processed.shape\n",
    "N, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ee73e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Range = [i for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70f7aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c021294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = [Range[2*i] for i in range(N//2)]\n",
    "J = [Range[2*i+1] for i in range(N//2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbd919ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed_I = X_processed[I]\n",
    "X_processed_J = X_processed[J]\n",
    "D_I = mixture_fractions[I]\n",
    "D_J = mixture_fractions[J]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23839544",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_diff = np.abs(D_I - D_J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9affb2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27288783532884875"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3b53558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7341"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = (D_diff >= 0.2)\n",
    "D.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7f7ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trn = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e820ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X_processed_I, dtype = torch.float64)\n",
    "Y = torch.tensor(X_processed_J, dtype = torch.float64)\n",
    "D = torch.tensor(D, dtype = torch.torch.int64)\n",
    "\n",
    "X_T = X[:n_trn,:]\n",
    "Y_T = Y[:n_trn,:]\n",
    "D_T = D[:n_trn]\n",
    "\n",
    "X_test = X[n_trn:,:]\n",
    "Y_test = Y[n_trn:,:]\n",
    "D_test = D[n_trn:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce328bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = d\n",
    "n_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1eb0f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ML(d, k, n_labels, \n",
    "           X_T, Y_T, D_T, D_T, \n",
    "           X_test, Y_test, D_test, D_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb30ce03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Tau:  tensor([0.1030], dtype=torch.float64, requires_grad=True)\n",
      "epoch 0: loss = 0.693306519043722\n",
      "train accuracy with noise 0.5113\n",
      "train accuracy without noise 0.5113\n",
      "test accuracy with noise 0.5092\n",
      "test accuracy without noise 0.5092\n",
      "epoch 1:\n",
      " norm of B.grad = 1.1906852803417347,\n",
      " B.grad.max = 0.6287875510156503,\n",
      " loss = 0.693306519043722\n",
      "tensor([0.1030], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.5113\n",
      "train accuracy without noise 0.5113\n",
      "test accuracy with noise 0.5092\n",
      "test accuracy without noise 0.5092\n",
      "epoch 5001:\n",
      " norm of B.grad = 0.009227351187506784,\n",
      " B.grad.max = 0.047838432158720995,\n",
      " loss = 0.641592935001861\n",
      "tensor([0.1030], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.7132\n",
      "train accuracy without noise 0.7132\n",
      "test accuracy with noise 0.7074\n",
      "test accuracy without noise 0.7074\n",
      "epoch 10001:\n",
      " norm of B.grad = 0.009227492459473081,\n",
      " B.grad.max = 0.04783795410657208,\n",
      " loss = 0.6415895928853288\n",
      "tensor([0.1030], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.7132\n",
      "train accuracy without noise 0.7132\n",
      "test accuracy with noise 0.7074\n",
      "test accuracy without noise 0.7074\n",
      "epoch 15001:\n",
      " norm of B.grad = 0.009227619515858066,\n",
      " B.grad.max = 0.04783752428157253,\n",
      " loss = 0.6415865850038888\n",
      "tensor([0.1030], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.7133\n",
      "train accuracy without noise 0.7133\n",
      "test accuracy with noise 0.7074\n",
      "test accuracy without noise 0.7074\n",
      "epoch 20001:\n",
      " norm of B.grad = 0.00922773379539571,\n",
      " B.grad.max = 0.047837138020804824,\n",
      " loss = 0.6415838779295897\n",
      "tensor([0.1031], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.7134\n",
      "train accuracy without noise 0.7134\n",
      "test accuracy with noise 0.7074\n",
      "test accuracy without noise 0.7074\n",
      "epoch 25001:\n",
      " norm of B.grad = 0.009227836589676852,\n",
      " B.grad.max = 0.04783679103183224,\n",
      " loss = 0.6415814415781164\n",
      "tensor([0.1031], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.7134\n",
      "train accuracy without noise 0.7134\n",
      "test accuracy with noise 0.7074\n",
      "test accuracy without noise 0.7074\n",
      "epoch 30001:\n",
      " norm of B.grad = 0.0092279290584522,\n",
      " B.grad.max = 0.047836479391625615,\n",
      " loss = 0.6415792488742674\n",
      "tensor([0.1031], dtype=torch.float64, requires_grad=True)\n",
      "train accuracy with noise 0.7134\n",
      "train accuracy without noise 0.7134\n",
      "test accuracy with noise 0.7074\n",
      "test accuracy without noise 0.7074\n"
     ]
    }
   ],
   "source": [
    "model.train(learning_rate = 5e-8, #4e-1, decay = 0.9 accuracy = 73.75% is the best so far\n",
    "            n_iters = 30001, \n",
    "            decay = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a6ae59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45123da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a186e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
